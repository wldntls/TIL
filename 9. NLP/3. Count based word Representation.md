# 자연어 처리 



## 3. 카운트 기반의 단어표현

### [1] 다양한 단어의 표현

#### (1) 단어의 표현 방법

- 국소 표현(=이산 표현 : Discrete Representation)

  - 해당 단어 자체만 보고, 특정값을 맵핑하여 단어를 표현하는 방법

- 분산 표현(=연속 표현 : Continuous Representation)

  - 그 단어를 표현하고자 주변을 참고하여 단어를 표현하는 방법

    

#### (2) 카운트 기반 방법

<img src= https://wikidocs.net/images/page/31767/wordrepresentation.PNG>



### [2] Bag of Words(BoW)

- 단어의 등장 순서를 고려하지 않은 빈도수 기반의 단어표현 방법

#### (1) Bag of Words란?

- 단어들의 순서를 고려하지 않고, 단어들의 출현 빈도에만 집중하는 텍스트 데이터의 수치화 표현 방법입니다. 

- BoW를 만드는 과정

  - 각 단어에 고유한 정수 인덱스를 부여합니다.
  - 각 인덱스의 위치에 단어 토큰의 등장 횟수를 기록한 벡터를 만듭니다.

  ````python
  from konlpy.tag import Okt
  import re
  okt = Okt()
  
  # 정규표현식을 통해 온점을 제거하는 정제 작업
  doc1 = "정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다."
  doc2 = "소비자는 주로 소비하는 상품을 기준으로 물가상승률을 느낀다."
  doc3 = doc1+''+doc2
  token = re.sub("(\.)","","정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다.")
  
  # OKT 형태소 분석기를 통해 토큰화 작업을 수행한 뒤에, token에다가 넣음
  token = okt.morphs(token)
  
  word2index = {}
  bow = []
  ````

  ````python
  for voca in token:
      # token을 읽으면서, word2index에 없는 단어는 새로 추가하고, 이미 있는 단어는 넘깁니다. 
      if voca not in word2index.keys():
          word2index[voca] = len(word2index)
          # print(word2index[voca])
          # print(word2index)
          # BoW 전체에 전부 기본값 1을 넣습니다.
          bow.insert(len(word2index)-1,1)
          
      else:
          # 재등장하는 단어의 인덱스
          index = word2index.get(voca)
          # print(index) # 결과 1, 4
          
          # 재등장한 단어는 해당하는 인덱스의 위치에 1을 더한합니다.
          bow[index] = bow[index] + 1
          # print(bow) # [1, 2, 1, 1, 1, 1, 1], [1, 2, 1, 1, 2, 1, 1, 1]
          # 인덱스 1번째와, 4번째에 횟수를 추가해주는 것 
          
  print(word2index)
  ````

  ````python
  # 결과
  {'정부': 0, '가': 1, '발표': 2, '하는': 3, '물가상승률': 4, '과': 5, '소비자': 6, '느끼는': 7, '은': 8, '다르다': 9}
  ````

  ````python
  # 단어에 대한 카운트
  bow
  ````

  ````python
  # 결과
  [1, 2, 1, 1, 2, 1, 1, 1, 1, 1]
  ````

  

#### (2) CountVectorizer 클래스로 BoW 만들기

````python
# 영어
from sklearn.feature_extraction.text import CountVectorizer
corpus = ['yow konw I want your love. because I love you.']
vector = CountVectorizer()

# 코퍼스로부터 각 단어의 빈도수를 기록
print(vector.fit_transform(corpus).toarray())

# 각 단어의 인덱스가 어떻게 부여되어 있는지를 출력
print(vector.vocabulary_)
````

````python
# 결과
[[1 1 2 1 1 1 1]]
{'yow': 6, 'konw': 1, 'want': 3, 'your': 5, 'love': 2, 'because': 0, 'you': 4}
````

````python
# 한국어
from sklearn.feature_extraction.text import CountVectorizer
corpus = ['정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다.'] # 공백을 기준으로 토큰하다보니 제대로 표현되지 않음
# (물가상승률과, 물가상승률은)이 다른 단어로 인식이 됨
vector = CountVectorizer()

# 코퍼스로부터 각 단어의 빈도수를 기록
print(vector.fit_transform(corpus).toarray())

# 각 단어의 인덱스가 어떻게 부여되어 있는지를 출력
print(vector.vocabulary_)
````

````python
# 결과
[[1 1 1 1 1 1 1]]
{'정부가': 6, '발표하는': 4, '물가상승률과': 2, '소비자가': 5, '느끼는': 0, '물가상승률은': 3, '다르다': 1}
````



#### (3) 불용어를 제거한 BoW 만들기

````python
# 사용자가 직접 정의한 불용어 사용

from sklearn.feature_extraction.text import CountVectorizer

text = ["Family is not an important thing. It's everything."]
vect = CountVectorizer(stop_words=["the", "a", "an", "is", "not"])
print(vect.fit_transform(text).toarray())
print(vect.vocabulary_)
````

````python
# 결과
[[1 1 1 1 1]]
{'family': 1, 'important': 2, 'thing': 4, 'it': 3, 'everything': 0}
````

````python
# CountVectorizer에서 제공하는 자체 불용어 사용

from sklearn.feature_extraction.text import CountVectorizer

text = ["Family is not an important thing. It's everything"]
vect = CountVectorizer(stop_words = "english")
print(vect.fit_transform(text).toarray())
print(vect.vocabulary_)
````

````python
# 결과
[[1 1 1]]
{'family': 0, 'important': 1, 'thing': 2}
````

````python
# NLTK에서 지원하는 불용어 사용

from sklearn.feature_extraction.text import CountVectorizer
from nltk.corpus import stopwords

text = ["Family is not an important thing. It's everything."]
sw = stopwords.words("english")
vect = CountVectorizer(stop_words = sw)
print(vect.fit_transform(text).toarray())
print(vect.vocabulary_)
````

````python
# 결과
[[1 1 1 1]]
{'family': 1, 'important': 2, 'thing': 3, 'everything': 0}
````



### [3] 문서 단어 행렬

- 행렬은 DTM
- 열행은 TDM

#### (1) 문서 단어 행렬의 표기법(Document-Term Matrix, DTM)



#### (2) 문서 단어 행렬의 한계

- 희소 표현(Sparse representation)
  - 원-핫 벡터나 단어 집합의 크기가 벡터의 차원이 되고 대부분의 값이 0이 되는 벡터입니다. 원-핫 벡터는 공간적 낭비와 계산 리소스를 증가시킬 수 있다는 점에서 단점을 가집니다. DTM 또한 이와 마찬가지입니다. 
- 단순 빈도 수 기반 접근



#### (3) TDM 실습









